---
title: "InformeNaiveBayesSVM"
author: "Proyecto"
date: "2023-04-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Prediccion de ataque mediante Naive Bayes y SVM

#### Preprocesamiento de datos

```{r}
#Librerias a utilizar
library(e1071)
library(caret)
db<-readRDS('dbLimpios.rds')
head(db,5)

```
***
La base de datos cuenta con *`r ncol(db)`* columnnas y *`r nrow(db)`* filas. Sin embargo, con este modelo el objetivo es determinar el tipo de ataque, si es benigno o no. Para ello podemos comprobar si los datos se encuentran balanceados. 

```{r }
barplot(prop.table(table(db$Label)),col=c("orange","blue"),
        legend.text=c("Ataque","Ataques malignos"))
```
***
Como se observa en la grafica anterior los datos se encuentran debidamente balanceados, ahora veremos que columnas nos son de utilidad. 

Para verificar que columnas podemos usar, existe el metodo de determinar la correlacion entre la variable a predecir con otras columnas, donde si se obtiene una correlacion positiva significa que esa columna tienda a crecer junto con la variable de ataque. 
```{r }
db$Label<-as.numeric(db$Label)
cor(db$L4_SRC_PORT,db$Label)
```
***
Como se observa la columna de L4_SRC_PORT no fue una buena variable a comparar debido que obtuvo un resultado negativo.
```{r }
# cor(db$L4_DST_PORT,db$Label)
# cor(db$PROTOCOL,db$Label)
# cor(db$TCP_FLAGS,db$Label)

df <- db[,-c(1,3,41,40)]


for (i in colnames(df)){
  print(i)
  print(cor(df[[i]],db$Label))
}
```
***
Tras obtener la correlacion con todas las variables se determino que las variables mas aceptables son, DST_TO_SRC_SECOND_BYTES,SHORTEST_FLOW_PKT, MAX_TTL,PROTOCOL,L7_PROTO,FLOW_DURATION_MILLISECONDS, DURATION_IN, DURATION_OUT y MIN_TTL. En base esto crearemos un nuevo dataframe para deteminar si el modelo es capaz de predicir el tipo de ataque. 

```{r }
data<-db[,c("DST_TO_SRC_SECOND_BYTES","SHORTEST_FLOW_PKT","MAX_TTL","PROTOCOL","L7_PROTO","FLOW_DURATION_MILLISECONDS","DURATION_IN","DURATION_OUT","MIN_TTL","Label")]

data$Label<-as.factor(data$Label)
str(data)

#Shuffle data
data<-data[sample(1:nrow(data)), ]
```
#### Prediccion usando Naive Bayes


```{r }
data<-data[1:300000,]
table(data$Label)

```

```{r}

# Separación de datos (55% entrenamiento, 15% validación y 30% pruebas)
set.seed(123) # Para reproducibilidad
trainIndex <- createDataPartition(data$Label, p = 0.55, list = FALSE)
train <- data[trainIndex,]
temp <- data[-trainIndex,]
validationIndex <- createDataPartition(temp$Label, p = 0.15, list = FALSE)
validation <- temp[validationIndex,]
test <- temp[-validationIndex,]

# Evaluación cruzada con K-10 folds para K = 10
set.seed(123) # Para reproducibilidad
folds <- createFolds(train$Label, k = 10)
summary(folds)

# SVM
set.seed(123) # Para reproducibilidad
acc_svm <- c()
precision_svm <- c()
recall_svm <- c()
f1_svm <- c()

#Evaluación cruzada con K-10 folds para K = 10
for (i in 1:10) {
  train_cv <- train[-folds[[i]], ]
  test_cv <- train[folds[[i]], ]
  modelosvm <- svm(Label~., data = train_cv)
  predi<-predict(modelosvm, test_cv)
  cm_svm <- confusionMatrix(as.factor(predi), as.factor(test_cv$Label))
  acc_svm <- c(acc_svm, cm_svm$overall['Accuracy'])
  precision_svm <- c(precision_svm, cm_svm$byClass['Precision'])
  recall_svm <- c(recall_svm, cm_svm$byClass['Recall'])
  f1_svm <- c(f1_svm, cm_svm$byClass['F1'])
}

# Métricas de evaluación para SVM
acc_svm_mean <- mean(na.omit(acc_svm))
acc_svm_mean
precision_svm_mean <- mean(na.omit(precision_svm))
precision_svm_mean
recall_svm_mean <- mean(na.omit(recall_svm))
recall_svm_mean
f1_svm_mean <- mean(na.omit(f1_svm))
f1_svm_mean

# Naive Bayes
set.seed(123) # Para reproducibilidad
acc_nb <- c()
precision_nb <- c()
recall_nb <- c()
f1_nb <- c()

for (i in 1:10) {
  train_cv <- train[-folds[[i]], ]
  test_cv <- train[folds[[i]], ]
  modelo_nb <- naiveBayes(Label~., data=train_cv)
  pred_nb <- predict(modelo_nb, newdata = test_cv)
  cm_nb <- confusionMatrix(as.factor(pred_nb), as.factor(test_cv$Label))
  acc_nb <- c(acc_nb, cm_nb$overall['Accuracy'])
  precision_nb <- c(precision_nb, cm_nb$byClass['Precision'])
  recall_nb <- c(recall_nb, cm_nb$byClass['Recall'])
  f1_nb <- c(f1_nb, cm_nb$byClass['F1'])
}

# Métricas de evaluación para Naive Bayes
acc_nb_mean <- mean(na.omit(acc_nb))
acc_nb_mean
precision_nb_mean <- mean(na.omit(precision_nb))
precision_nb_mean
recall_nb_mean <- mean(na.omit(recall_nb))
recall_nb_mean
f1_nb_mean <- mean(na.omit(f1_nb))
f1_nb_mean

```
